# Monitoring with prometheus


### **What is the kube-prometheus-stack?**  
The **kube-prometheus-stack** is a Helm chart that deploys a **complete monitoring solution** for Kubernetes clusters using **Prometheus**, **Alertmanager**, **Grafana**, and other monitoring components. It provides out-of-the-box Kubernetes monitoring with pre-configured dashboards, recording rules, and alerts.

This stack includes:  
- **Prometheus**: Collects and stores time-series data.  
- **Alertmanager**: Handles alerts generated by Prometheus.  
- **Grafana**: Provides dashboards and visualization.  
- **node-exporter**: Collects node-level metrics.  
- **kube-state-metrics**: Exposes Kubernetes object metrics.  
- **Prometheus Operator**: Manages and automates Prometheus deployments.  

---

### **Exploring the kube-prometheus-stack with kubectl**  

If the stack is deployed in the `kube-prometheus` namespace, you can explore its components using `kubectl`.

#### **1. Check All Resources in the Namespace**
```sh
kubectl get all -n kube-prometheus
```
This lists all the running pods, services, and deployments.

#### **2. View Prometheus Pods**
```sh
kubectl get pods -n kube-prometheus -l app.kubernetes.io/name=prometheus
```
This filters out only the Prometheus pods.

#### **3. Access Prometheus UI**
Port-forward the Prometheus service to your local machine:
```sh
kubectl port-forward -n kube-prometheus svc/kube-prometheus-kube-prome-prometheus 9090
```

Then, open **http://localhost:9090** in a browser.

#### **4. Access Grafana Dashboards**
First, find the Grafana pod:
```sh
kubectl get pods -n kube-prometheus -l app.kubernetes.io/name=grafana
```
Port-forward the Grafana service:
```sh
kubectl port-forward -n kube-prometheus svc/kube-prometheus-grafana 3000:80
```
Then, open **http://localhost:3000** in a browser. The default login is usually:  
- **User**: `admin`  
- **Password**: Can be retrieved with:  
  ```sh
  kubectl get secret -n kube-prometheus kube-prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 --decode
  ```

#### **5. Explore Available CustomResourceDefinitions (CRDs)**
The Prometheus Operator introduces several custom resources:
```sh
kubectl get crds | grep monitoring.coreos.com
```

For example, to view Prometheus instances managed by the operator:
```sh
kubectl get prometheus -n kube-prometheus
```

---

### **Summary**
1. Use `kubectl get all -n kube-prometheus` to list resources.
2. Use `kubectl port-forward` to access UIs (Prometheus, Grafana, Alertmanager).
3. Check Prometheus and Alertmanager configurations using `kubectl get prometheus` and `kubectl get alertmanager`.
4. View dashboards in Grafana using the default credentials.


# Working with ServiceMonitors

1. Deploy a Sample Application with Metrics

This is a simple Go application that exposes metrics on port 8080. The service makes the /metrics endpoint available inside the cluster.

```sh
kubectl apply -f service-monitors/example-deployment.yaml
```

3. Create a ServiceMonitor for Prometheus
The ServiceMonitor tells Prometheus to scrape the /metrics endpoint from metrics-app-service.

```sh
kubectl apply -f service-monitors/servicemonitor.yaml
```

5. Verify That Prometheus is Scraping the Target

Open Prometheus (port-forward if needed):
```sh 
kubectl port-forward -n kube-prometheus svc/kube-prometheus-kube-prome-prometheus 9090
```
Go to http://localhost:9090/targets
Check if metrics-app-service appears under the active targets.

You can check the values of your metrics with e.g. `go_memstats_buck_hash_sys_bytes{namespace="user1"}` under the query tab. Ensure that your namespace is set correctly. You will also find these values in Grafana! 

Key Points

✅ The Deployment runs a metrics-enabled app.
✅ The Service exposes the app inside the cluster.
✅ The ServiceMonitor configures Prometheus to scrape the metrics.
✅ Prometheus automatically picks up the target if the release label matches.